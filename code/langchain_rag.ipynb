{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import nltk\n",
    "from langchain_text_splitters import NLTKTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from IPython.display import Markdown as md\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  \n",
    "key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1'}, page_content='類神經網路基礎\\n王豐緒\\n銘傳大學資工系'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2'}, page_content='學習目標\\n• 理解類神經元的基本結構與運作方式\\n• 理解何謂Perceptron類神經網路\\n• 理解類神經的學習方式\\n• 理解類神經的訓練與測試過程\\n• 理解矩陣運算與類神經的關聯\\n2'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3'}, page_content='大綱\\n• 類神經元的結構與運作\\n• Perceptron類神經網路\\n• 學習方程式\\n• 學習速率的選擇\\n• 訓練與測試\\n• 訓練階段(backward process)\\n• 測試階段(Forward Process)\\n• 矩陣運算與類神經\\n• 小結\\n3'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 3, 'page_label': '4'}, page_content='大腦神經元(NEURONS)\\n• 神經元\\n• 大腦中的處理單元（1000億個，1011）\\n• 每個通過突觸與其他神經元相連（1千兆\\n個，1014）\\n• 具有可塑性和堅韌的操作性\\n• 經由學習，修改突觸強度\\n• 經由學習，建立新連接 (突觸，Synapse)\\n4\\n(source: Wiki)\\nneuron\\n決定是否觸發\\n突觸'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 4, 'page_label': '5'}, page_content='類神經元(ARTIFICIAL NEURONS)\\n• McCulloch and Pitts Neurons\\n5\\nh\\nx1\\nx2\\nxm\\nw1\\nw2\\nwm\\nO\\n…\\n-1\\n𝜃\\n偏值(bias)\\nneuron\\n在所有输入都是零的情况下需要\\n𝑜 = 𝑔(ℎ) = ቊ1 𝑖𝑓 ℎ > 0\\n0 𝑖𝑓 ℎ ≤ 0\\nℎ = \\u0dcd\\n𝑖\\n𝑊𝑖𝑋𝑖 − 𝜃\\n𝑔 : 激活函數 (activation function)\\nX: the input vector: [x1, x2, …, xm, -1]\\nW: the weight vector: [w1, w2, …, wm, 𝜃]\\n𝑜 = 𝑔(𝑊 ⊙ 𝑋)\\n⊙ : the inner product of 𝑊，𝑋'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 5, 'page_label': '6'}, page_content='PERCEPTRON類神經網路\\n• 最早的多神經元網路\\n• 啟發式學習法則\\n6\\n𝑥𝑖: 網路輸入\\n𝑦𝑗: 網路輸出\\n𝑡𝑗 : 真正的輸出\\n𝜂 : 學習速率 (learning rate)\\n𝑥𝑖 𝑦𝑗\\n△ 𝑤𝑖𝑗= −𝜂(𝑦𝑗 − 𝑡𝑗) ∙ 𝑥𝑖 WHY?\\n學習方程式\\n𝑦𝑗 − 𝑡𝑗\\n高估(𝑦𝑗 > 𝑡𝑗)\\n低估(𝑦𝑗 < 𝑡𝑗)\\n降低訊號強度z\\n增強訊號強度z\\n𝑧 = 𝑥𝑖𝑤𝑖𝑗目標\\n-\\n+\\n𝑥𝑖 𝑛𝑗\\n𝑤𝑖𝑗\\n𝑦𝑗\\n𝑧 = 𝑥𝑖𝑤𝑖𝑗'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 6, 'page_label': '7'}, page_content='學習速率的選擇\\n• 較小的 learning rate\\n• 學習較慢\\n• 較能容忍資料雜訊和資料不一致性\\n• 較大的 learning rate\\n• 較不穩定\\n• 實務上\\n• 可嘗試 0.1 < 𝜂 <0.4\\n7\\n△ 𝑤𝑖𝑗= −𝜂(𝑦𝑗 − 𝑡𝑗) ∙ 𝑥𝑖'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 7, 'page_label': '8'}, page_content=\"訓練(TRAIN)與測試(TEST)\\n• 訓練階段\\n• 將訓練數據x輸入到類神經網路中\\n並更新權重直到輸出正確答案y\\n• 測試階段\\n• 將測試數據x輸入到類神經網路中\\n並取得網路輸出y'\\n8\\n類神經網路\\n(W)x y\\n類神經網路\\n(W)x y'\"),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9'}, page_content='訓練階段(BACKWARD PROCESS)\\n• 輸入訓練資料 : 𝐷(𝑀+1)×𝑁\\n• N筆 (M+1)-input 向量\\n• 加入偏值向量(-1)\\n• 輸出訓練資料 : 𝐿𝑂×𝑁\\n• 權重向量(Weight Matrix)\\n• 𝑊(𝑀+1)×𝑂\\n• 加入偏值權重(B)(bias weight): 𝐵1×𝑂\\n• 網路輸出Y : 𝑌𝑂×𝑁\\n• 總權重修正量矩陣: ∆𝑊𝑂×(𝑀+1)\\n9\\n𝑊𝑂×(𝑀+1)\\n𝑇 × 𝐷(𝑀+1)×𝑁= 𝐻𝑂×𝑁\\n𝑌𝑂×𝑁= 𝑔(𝐻𝑂×𝑁)\\n∆𝑊=−𝜂𝐷(𝑀+1)×𝑁 × (𝑌𝑂×𝑁 − 𝐿𝑂×𝑁)𝑇\\nB   \\nWM\\nO\\n1\\n-1\\nD\\nN\\nM LO\\nN\\n1\\nYO\\nN\\n𝑥𝑖 𝑦𝑗'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10'}, page_content='訓練階段(BACKWARD PROCESS)\\n10\\n−1\\nbias\\nD O\\nB   \\nWM\\nO\\n1\\nY O\\nN\\n-11\\nD\\nN\\nM\\nN\\nLO\\n△ 𝒘𝒊𝒋= −𝜼(𝒚𝒋 − 𝒕𝒋) ∙ 𝒙𝒊'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11'}, page_content='訓練階段(BACKWARD PROCESS)\\n11\\nx1\\nx2\\n-1\\ny1\\ny2\\n0.4\\n0.8\\n0.1\\n0.3\\n0.5\\n0.2\\nD=\\n0 1 1\\n1 0 1\\n−1 −1 −1\\nL= 1 0 1\\n1 0 0 W=\\n0.4 0.8\\n0.1 0.3\\n0.5 0.2\\n𝐻 = 𝑊𝑇 × 𝐷 = 0.4 0.1 0.5\\n0.8 0.3 0.2 ×\\n0 1 1\\n1 0 1\\n−1 −1 −1\\n= −0.4 −0.1 0\\n0.1 0.6 0.9\\n𝑌= 𝑔 𝐻 = 0 0 0\\n1 1 1\\n∆𝑊=−𝜂𝐷 𝑀+1 ×𝑁 × 𝑌𝑂×𝑁 − 𝐿𝑂×𝑁 𝑇\\n= −0.1 ∙\\n0 1 1\\n1 0 1\\n−1 −1 −1\\n×\\n−1 0\\n0 1\\n−1 1\\n= −0.1 ∙\\n−1 2\\n−2 1\\n2 −2\\n=\\n0.1 −0.2\\n0.2 −0.1\\n−0.2 0.2\\n1 1 0\\n1 0 1\\n0 0 0\\n1 1 1'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12'}, page_content='感知器的更新訓練演算法\\n12\\nStart\\nData size = N\\nMini-batch size = m\\nepochs: e\\nGenerate \\n𝑁\\n𝑚 random batches  of \\nsamples\\nNO\\nTrain with next batch\\nFinished \\nall\\nbatches?\\nNO\\nYES\\nYES\\nEnd\\nFinished \\ne\\nepochs?\\n(one epoch)'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13'}, page_content='測試階段(FORWARD PROCESS)\\n13\\n−1\\nbias\\nO\\nB   \\nWM\\nO\\n1\\nY O\\nN\\n-11\\nD\\nN\\nM\\n給定一組包含 N 個 M 輸入向量的輸入數據（D）和標籤數據（L），權重矩陣（W），\\n計算網絡的輸出數據（Y）\\nN\\nL O\\nD\\nW\\nB'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14'}, page_content='測試階段(FORWARD PROCESS)\\n• 輸入測試資料 : 𝐷(𝑀+1)×𝑁\\n• N筆 (M+1)-input 向量\\n• 加入偏值向量(-1)\\n• 輸出測試資料 : 𝐿𝑂×𝑁\\n• 權重向量(Weight Matrix)\\n• 𝑊(𝑀+1)×𝑂\\n• 加入偏值權重(B)(bias weight): 𝐵1×𝑂\\n• 網路輸出Y : 𝑌𝑂×𝑁\\n• 方差矩陣(Total Squared Error Matrix): 𝐸𝑁\\n14\\n𝑊𝑂×(𝑀+1)\\n𝑇 × 𝐷(𝑀+1)×𝑁= 𝑍𝑂×𝑁\\n𝑌𝑂×𝑁= 𝑔(𝑍𝑂×𝑁)\\n𝐸𝑁= 𝑆𝑈𝑀𝑐𝑜𝑙\\n2 (𝑌𝑂×𝑁 − 𝐿𝑂×𝑁)\\nB   \\nWM\\nO\\n1\\n-1\\nD\\nN\\nM LO\\nN\\n1\\nYO\\nN\\ng Y'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15'}, page_content='測試階段(FORWARD PROCESS)\\n15\\n𝑍 = 𝑊𝑇 × 𝐷 = 5 8 7\\n6 9 10 ×\\n1 3\\n2 4\\n−1 −1\\n= 14 32\\n14 44\\n𝑌= 𝑔 𝑍 = 1 1\\n1 1\\n𝐸𝑁= 𝑆𝑈𝑀𝑐𝑜𝑙\\n2 𝑌 − 𝐿 = 𝑆𝑈𝑀𝑐𝑜𝑙\\n2 1 1\\n1 1 − 1 3\\n2 4 = 𝑆𝑈𝑀𝑐𝑜𝑙\\n2 0 −2\\n−1 −3 = [1 13]\\n-1\\n1\\n2\\n3\\n4\\n7\\n5\\n6\\n8\\n9\\n10\\n𝐷 =\\n1 3\\n2 4\\n−1 −1\\n𝑊 =\\n5 6\\n8 9\\n7 10\\n1\\n1\\n1\\n1\\n𝐿 = 1 3\\n2 4'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16'}, page_content='測試階段(FORWARD PROCESS)\\n16\\nx1\\nx2\\n-1\\ny1\\ny2\\n0.4\\n0.8\\n0.1\\n0.3\\n0.5\\n0.2\\nD=\\n0 1 1\\n1 0 1\\n−1 −1 −1\\nL= 1 0 1\\n1 0 0 W=\\n0.4 0.8\\n0.1 0.3\\n0.5 0.2\\n𝑍 = 𝑊𝑇 × 𝐷 = 0.4 0.1 0.5\\n0.8 0.3 0.2 ×\\n0 1 1\\n1 0 1\\n−1 −1 −1\\n= −0.4 −0.1 0\\n0.1 0.6 0.9\\n𝑌= 𝑔 𝐻 = 0 0 0\\n1 1 1\\n𝐸 = 𝑆𝑈𝑀𝑐𝑜𝑙\\n2 ( 0 0 0\\n1 1 1 − 1 0 1\\n1 0 0 )=𝑆𝑈𝑀𝑐𝑜𝑙\\n2 −1 0 −1\\n0 1 1 = [1 1 2]'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17'}, page_content='矩陣運算與類神經\\n• 為什麼要以矩陣視角看待神經網路操作？\\n• 延伸至對 TensorFlow 的觀點（何謂張量(Tensor)？）\\n• 對於在晶片上（例如 GPU）進行高速計算很有用\\n• 在訓練階段，權重更新矩陣是由所有 N 筆訓練數據與原始網路權重計算收集而來\\n• 如果 N 很大會發生什麼？\\n• 如果選擇每個單一訓練數據來更新權重呢？\\n17\\nSee how matrix multiplication can be reduced to O(N) from O(N3) with parallel computation \\n(https://www.sciencedirect.com/science/article/pii/0167819189900574)'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18'}, page_content='小結\\n• 單一神經元的模型（McCulloch和Pitts 神經元）\\n• 神經元的運作方式\\n• 感知器\\n• 如何透過導出學習規則來訓練神經網路\\n• 測試感知器，看神經網絡如何進行訓練和操作\\n• 初始化權重\\n• 訓練\\n• 測試\\n• 學習將神經網路操作視為矩陣操作\\n• 學習典型的訓練過程\\n• 小批次大小\\n• 執行周期的次數\\n18'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19'}, page_content='參考文獻\\n• [1] Machine Learning: An Algorithmic Perspective, by Stephen Marsland, \\npublished by CRC Press (2014).\\n19'),\n",
       " Document(metadata={'producer': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creator': '適用於 Microsoft 365 的 Microsoft® PowerPoint®', 'creationdate': '2024-02-19T15:15:35+08:00', 'title': '深度學習簡介', 'author': 'fhwang', 'moddate': '2024-02-19T15:15:35+08:00', 'source': '../data/1neural_network.pdf', 'total_pages': 20, 'page': 19, 'page_label': '20'}, page_content='Q&A\\n20')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model = ChatGoogleGenerativeAI(google_api_key=key, \n",
    "                                   model=\"gemini-1.5-pro-latest\")\n",
    "loader = PyPDFLoader(\"../data/1neural_network.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "text_splitter = NLTKTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "print(len(chunks))\n",
    "print(type(chunks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27887/164989724.py:3: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n",
      "/tmp/ipykernel_27887/164989724.py:4: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db_connection = Chroma(persist_directory=\"../chroma_db_\", embedding_function=embedding_model)\n"
     ]
    }
   ],
   "source": [
    "embedding_model = GoogleGenerativeAIEmbeddings(google_api_key=key, model=\"models/embedding-001\")\n",
    "db = Chroma.from_documents(chunks, embedding_model, persist_directory=\"../chroma_db_\")\n",
    "db.persist()\n",
    "db_connection = Chroma(persist_directory=\"../chroma_db_\", embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.vectorstores.base.VectorStoreRetriever'>\n"
     ]
    }
   ],
   "source": [
    "retriever = db_connection.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "print(type(retriever))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"\"\"You are a teacher in Scaffolding Instruction education.\n",
    "                  Given a context and question from user,\n",
    "                  you should answer based on the given context.\"\"\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"\"\"Answer the question based on the given context.\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    Answer: \"\"\")\n",
    "])\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | chat_template\n",
    "    | chat_model\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided text, a neural network is inspired by biological neurons in the brain.  Artificial neurons, like their biological counterparts, receive inputs (x1, x2,...xm), each weighted (w1, w2,...wm), and a bias (𝜃). These weighted inputs are summed and passed through an activation function (g) to produce an output (o).  The activation function determines whether the neuron \"fires\" (outputting 1) or not (outputting 0) based on whether the weighted sum of inputs exceeds a threshold.  Learning in artificial neural networks involves adjusting the weights and bias.  The text mentions the McCulloch and Pitts neuron model as an example of an artificial neuron and describes how biological neurons connect through synapses, the strengths of which are modified through learning.  While the text outlines topics related to perceptron neural networks, learning equations, and training/testing phases, it does not provide a comprehensive definition of a neural network beyond the individual neuron model."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"\"\"Please summarize what is a neural network\"\"\")\n",
    "md(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "提供的上下文並沒有詳細解釋權重，只提到初始化權重、訓練階段會更新權重以得到正確答案，以及類神經網路用(W)代表權重。並沒有說明權重如何計算、更新，或其代表的意義。\n",
       "\n",
       "要理解權重，需要補充以下資訊：\n",
       "\n",
       "* **權重的意義:**  在類神經網路中，權重代表輸入數據的重要性。每個輸入值都會乘以一個權重，然後加總起來，再經過激活函數處理，最終產生輸出。權重越大，表示對應的輸入值對輸出的影響越大。\n",
       "\n",
       "* **權重的初始化:**  在開始訓練之前，需要初始化權重。常見的初始化方法包括隨機初始化、使用特定分佈（例如高斯分佈）初始化等。初始化的值會影響訓練的效率和最終結果。\n",
       "\n",
       "* **權重的更新:**  在訓練過程中，類神經網路會根據預測結果和實際結果之間的差異（損失函數）來調整權重。這個調整過程通常使用反向傳播算法和梯度下降等優化算法。目標是找到一組權重，使得損失函數最小化，也就是讓網路的預測結果盡可能接近實際結果。\n",
       "\n",
       "總之，權重是類神經網路的核心組成部分，它們決定了網路如何處理輸入數據並產生輸出。透過訓練過程不斷調整權重，網路可以學習到從輸入到輸出的映射關係。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"\"\"詳細解釋權重\"\"\")\n",
    "\n",
    "md(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
